<!DOCTYPE html>
<html lang="en" data-theme="light">
  <head>
    <meta charset="utf-8">
    <meta content="ie=edge" http-equiv="x-ua-compatible">
    <meta content="width=device-width, initial-scale=1" name="viewport">
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha512-SnH5WK+bZxgPHs44uWIX+LLJAJ9/2PkPKZ5QiAj6Ta86w+fsb2TkcmfRyVX3pBnMFcV7oQPJkl9QevSCWr3W6A==" crossorigin="anonymous" referrerpolicy="no-referrer" />

    <!-- Highlight.js Tokyo Night (dark) from jsDelivr / highlight.js CDN -->
<link rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.11.1/build/styles/tokyo-night-dark.min.css">


    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-SLLMJ5YC4K"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-SLLMJ5YC4K');
</script>

  </head>

  <body class="bg-slate-50 text-base-content min-h-screen p-6">
    <div class="flex justify-between items-center w-full">
  <a href="http://localhost:4000" class="flex-1">
    <img class="w-12 h-12 rounded-full" src="/assets/images/headshot.jpg" />
  </a>

  <div class="hidden sm:flex w-fit justify-center items-center bg-slate-200 p-2 rounded-full font-semibold">
    <a href="/" class="hover:bg-slate-300 py-2 px-4 rounded-full">Home</a>
    <a href="https://drive.google.com/file/d/10v_i5GDWsbjHuOF4qq_nvTrEcAoZPUfY/view?usp=sharing" target="_blank" class="hover:bg-slate-300 py-2 px-4 rounded-full">Resume</a>
    <a href="javascript:window.location.href='mailto:' + atob('c3BlbmNlcmxsb3lkZGl4b25AZ21haWwuY29t')" class="hover:bg-slate-300 py-2 px-4 rounded-full">Contact</a>
  </div>

  <div class="hidden sm:flex gap-4 flex-1 justify-end">
    <a href="javascript:window.location.href='mailto:' + atob('c3BlbmNlcmxsb3lkZGl4b25AZ21haWwuY29t')">
      <i class="fa-solid fa-xl fa-envelope"></i>
    </a>


    <a href="http://localhost:4000/feed.xml">
      <i class="fa-solid fa-xl fa-rss"></i>
    </a>
  </div>

  <label class="block sm:hidden relative z-40 cursor-pointer px-3 py-6 flex-1 flex justify-end" for="mobile-menu">
    <input class="peer hidden" type="checkbox" id="mobile-menu" />
    <div
        class="relative z-50 block h-[2px] w-7 bg-black bg-transparent content-[''] before:absolute before:top-[-0.35rem] before:z-50 before:block before:h-full before:w-full before:bg-black before:transition-all before:duration-200 before:ease-out before:content-[''] after:absolute after:right-0 after:bottom-[-0.35rem] after:block after:h-full after:w-full after:bg-black after:transition-all after:duration-200 after:ease-out after:content-[''] peer-checked:bg-transparent before:peer-checked:top-0 before:peer-checked:w-full before:peer-checked:rotate-45 before:peer-checked:transform after:peer-checked:bottom-0 after:peer-checked:w-full after:peer-checked:-rotate-45 after:peer-checked:transform"
        >
    </div>
      <div
          class="fixed inset-0 z-40 hidden h-full w-full bg-black/50 backdrop-blur-sm peer-checked:block"
          >
          &nbsp;
      </div>
        <div
            class="fixed top-0 right-0 z-40 h-full w-full translate-x-full overflow-y-auto overscroll-y-none transition duration-500 peer-checked:translate-x-0"
            >
            <div class="float-right min-h-full w-[80%] bg-slate-50 px-8 pt-24 shadow-2xl">
              <menu class="flex flex-col gap-4 text-xl">
                <li><a href="/" class="flex rounded-full py-2 px-6 hover:bg-slate-200">Home</a></li>
                <li><a href="https://drive.google.com/file/d/10v_i5GDWsbjHuOF4qq_nvTrEcAoZPUfY/view?usp=sharing" target="_blank" class="flex rounded-full py-2 px-6 hover:bg-slate-200">Resume</a></li>
                <li><a href="javascript:window.location.href='mailto:' + atob('c3BlbmNlcmxsb3lkZGl4b25AZ21haWwuY29t')" class="flex rounded-full py-2 px-6 hover:bg-slate-200">Contact</a></li>
              </menu>
            </div>
        </div>
  </label>
</div>


    <main class="container mx-auto">
      <div class="max-w-screen-md mx-auto mt-24">
  <div class="flex flex-col gap-2 sm:mt-12 mb-12">
    <h1 class="text-6xl text-primary tracking-tight mb-4">Understanding Convolutional Neural Networks</h1>
    <time class="">10 Nov 2017</time>
  </div>

  <article class="mx-auto prose lg:prose-xl text-base-content">
    <p>In the past few posts, I‚Äôve taken a dive into how neural networks work. We even built a neural net that could learn to recognise handwriting by breaking it down into a huge array of the pixels in the image, and representing the colour of the pixel as a value from 0-1.</p>

<p>Our last model got 96% accuracy, but it turns out we can do even better with a different type of neural network that is especially good at images; the convolutional neural network.</p>

<p>In this post we‚Äôll explore the concept of convolutional neural networks, how they work, what makes them good at dealing with images and build our own using Tensorflow.</p>

<h2 id="what-is-convolution">What is convolution?</h2>

<p>Convolution simply means combining two things to form a third thing, which is a modified version of one of the first things. Let‚Äôs look at how it works in detecting edges in an image‚Ä¶</p>

<p><img src="/assets/images/understanding_convolutional_neural_networks/conv_filter.gif" alt="Using a filter to detect edges" /></p>

<p>Let‚Äôs take a small sample of our larger image. We‚Äôll zoom in on a 5x5 grid of the top corner of our image. Our image will be our first input, which we‚Äôll need to convolve with some other input, to create our output. That second input will be called our filter. A filter is simply a smaller grid of weights, and we‚Äôll slide this over our 5x5 image sample like in the gif above.</p>

<p>You can see the weights written in red. At each step, we‚Äôll take each number in our 3x3 window of our image and multiply it by the corresponding weight in our filter cell. So in the top left hand corner, our value is 1, and our filter value is 1, therefore, 1x1 will be 1, and we‚Äôll add this to the next value where our image value is 1 but our filter value is 0.</p>

<p>We‚Äôll repeat the process until we have a total for the values within our filter. This ends up giving us a total of 4. We‚Äôll write this in our output, and slide our filter one cell over to the right and repeat to get the next value. Once we reach the end of the row, we‚Äôll slide one cell down and back to the left and repeat the process. Repeating this for a 5x5 grid will give us a 3x3 output.</p>

<p>The different values in our filter enhance differences in the image. We can use a filter to detect edges for example by having values in the first and third columns of our 3x3 grid that result in a negative total, and values in the middle column that results in a positive total when passed over an edge. This would result in an output something like this, showing a dark to light to dark edge‚Ä¶</p>

<pre><code class="language-python">0,1,0
0,1,0
0,1,0
</code></pre>

<p>That‚Äôs really all there is to it; filters give us a convenient way to find certain features in an image by their light/dark difference represented numerically. But which filters to use? Well this is something that we will let our neural network learn. During training, it will learn the right features for the job.</p>

<h2 id="padding">Padding</h2>

<p>When we slide our filter over our image, we‚Äôll only touch on the corner pixels once, but the middle pixels end up in lots of our windows. This is a problem as this is giving more importance to the middle pixels than the outer ones. We want every pixel to have an even influence in our calculations. Also, our output is now 3x3, so we‚Äôve lost some size. How do we solve these issues?</p>

<p>The answer is padding. We‚Äôll add an extra border of pixels around our image. This means that when we slide over our image with our filter, we not only are able to reach our original edges the same amount of times as we reach the middle pixels, but that our output ends up being the same size as our input. When the output is the same as the input size, this is called <em>same</em> padding. When we add no padding, we call this <em>valid</em> padding.</p>

<p><img src="/assets/images/understanding_convolutional_neural_networks/padding.png" alt="Padding a 6x6 image with 0 pixels" /></p>

<p>Padding is another hyperparameter that we can tune for our network. It doesn‚Äôt just have to be one pixel we pad with; a 5x5 image will require a padding of 2 to give a 5x5 output.</p>

<h2 id="strides">Strides</h2>

<p>In our example we took a 5x5 grid and slid our filter over one cell at a time. The distance we move our filter is called a stride. In our example we had a stride of one; moving one cell at a time. Setting the stride to 2 would jump our filter two cells across, and when we reached the end of a row, we would jump two rows down.</p>

<h2 id="dealing-with-rgb-images">Dealing with RGB images</h2>

<p>As any RGB images we input will have three dimensions (one each for red, green and blue), our images are no longer 5x5, but they are 5x5x3. To deal with this, we‚Äôll do the same with our filters, having a filter for each channel.This is why you often see convolutional neural nets drawn with cubes or three dimensional objects instead of squares. The cube simply represents the channels of our image, or that our image is three dimensional (in the sense that colour is our third dimension). Using these 3d filters, we can also start to recognise features in different colours by applying different filters to different colour channels.</p>

<h2 id="pooling">Pooling</h2>

<p>Pooling is a technique that can be used to speed up our network and reduce computation.</p>

<p>We‚Äôll take our input and split it into different regions (in this example, we‚Äôre taking a filter size of 2x2 and a stride of 2), and we‚Äôll simply take the largest number in the region. This is called <em>max pooling</em>, as we‚Äôre taking the maximum value.</p>

<p>Max values usually represent that a feature has been detected so we can keep this, and move it to our new output. Our filter size and stride are also tunable hyperparameters here, other than this, we have no parameters to learn for max pooling, it‚Äôs just a fixed computation which we apply through each channel.</p>

<p><img src="/assets/images/understanding_convolutional_neural_networks/max_pooling.png" alt="An example of max pooling" /></p>

<h2 id="forward-propagation">Forward Propagation</h2>

<p>The weights for our 3x3x3 filters will play the role of standard weights in forward propagation of our network. We‚Äôll add a bias to give us a total of 28 weights (3x3x3 = 27 + 1 = 28) and apply an activation function as normal. Let‚Äôs work through an example</p>

<p>Let‚Äôs assume that we have a small input image of 39x39 pixels, with 3 channels (RGB), giving us a 39x39x3 input into our convolutional neural net.</p>

<p>In our first layer, we‚Äôll use a set of 3x3 filters to pass over our image. We‚Äôll use a stride of 1 and no padding. We‚Äôll have 10 filters in our first layer.</p>

<p>This means our activations for our first layer will be 37x37x10. The height and width are explained by the moves we can make with a stride of one, we lose a little bit of size because we cant overlap our filter over the edges. Our depth comes from the fact this this activation represents a stack of learned filters and since we learned 10 filters, our output for this layer will be 10 filters deep.</p>

<p>Our formula for our output of a layer looks like this‚Ä¶</p>

<pre><code class="language-python"># nh = height of input in pixels (39)
# p  = padding
# f  = filter size (3)
# s  = stride size (1)

((nh + (2 * p) - f) / s) + 1 # This + 1 is adding our bias
</code></pre>

<p>We can also change <code>nh</code> for <code>nw</code> to get the width.</p>

<p>In our second layer, we‚Äôll use a 5x5 filter, with a stride of 2, and no padding to apply 20 filters. We can follow our formula above to get our output size‚Ä¶</p>

<pre><code class="language-python">nh = 37
p  = 0
f  = 5
s  = 2

((nh + (2 * p) - f) / s) + 1

or

((37 + (2 * 0) - 5) / 2) + 1
</code></pre>

<p>This gives us an output of 17x17x20. Because we used a bigger stride this time, our size shrank quite dramatically and our depth grew because we applied more filters.</p>

<p>Let‚Äôs do one more layer. We‚Äôll input our 17x17x20 and use a 5x5 filter, with a stride of 2 to apply 40 filters. Using the same formula, we get a 7x7x40 output.</p>

<p>After we perform a few layers of convolution, we‚Äôll take our output and flatten it into a single long array. A 7x7x40 array will unroll into a 1960x1 list of values which we can then feed into a few layers of standard neurons with a softmax function to get our final output.</p>

<h2 id="putting-it-all-together">Putting it all together</h2>

<p>Traditionally, we‚Äôll intersperse our pooling operations with our convolutional layers and then feed the whole thing to a few fully connected layers, before using softmax to give our final output. Our pooling operation isn‚Äôt really counted as a layer as it doesn‚Äôt have any weights to learn, so we‚Äôll often group a convolutional and a pooling operation as part of the same layer.</p>

<table>
  <thead>
    <tr>
      <th>Layer</th>
      <th>Size</th>
      <th>Settings</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Input</td>
      <td>32x32x3</td>
      <td>f=5, s=1</td>
    </tr>
    <tr>
      <td>Conv1</td>
      <td>28x28x8</td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>MaxPool</td>
      <td>14x14x8</td>
      <td>f=2, s=2</td>
    </tr>
    <tr>
      <td>Conv2</td>
      <td>10x10x16</td>
      <td>f=5, s=1</td>
    </tr>
    <tr>
      <td>MaxPool</td>
      <td>5x5x16</td>
      <td>f=2, s=2</td>
    </tr>
    <tr>
      <td>Full</td>
      <td>120x1</td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>Full</td>
      <td>84x1</td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>Softmax</td>
      <td>10x1</td>
      <td>¬†</td>
    </tr>
  </tbody>
</table>

<p>Note we‚Äôre outputting to 10 neurons, so in this example we‚Äôre assuming you‚Äôd want to classify something as one of 10 classes, for example, our 0-9 hand written number recognition task.</p>

<p>Also notice the size of our data as it passes through our network. It stays relatively small. If we‚Äôd have just unrolled our 32x32x3 image into one long vector, and fed it to even more neurons, which get fed to even more neurons, the amount of weights in our network would be huge. We‚Äôd face our exponential complexity problem again we discussed a few posts back in Neural Networks from Scratch.</p>

<p>Instead, the only parameters we learn are those of our relatively small 3x3 or 5x5 filters, and while we may have a lot of them, it doesn‚Äôt get out of hand anywhere near as quickly as if we treated each pixel as a neuron.</p>

<h2 id="summary">Summary</h2>

<p>Convolutional networks allow us to learn filters, which can then be reused as we pass them across the network looking for interesting features. As we combine these features together we can detect more high level features and combine the result to get even more higher level information about the features. Detected edges, when combined, can tell us where a curve is, and detected curves, when combined, can tell us where a nose or an eye is, and detected noses and eyes when combined can tell us the presence of a face.</p>


  </article>

  <div role="alert" class="mt-24 mb-12 alert alert-error alert-dash alert-vertical sm:alert-horizontal">
  üëç
  <div>
    <h3 class="font-bold">Thanks for reading</h3>
    <p class="">You can follow me here for my latest thoughts and projects</p>
  </div>
  <div class="flex items-center gap-4">
    <a href="https://github.com/spencerldixon" target="_blank">
      <i class="fa-brands fa-github fa-xl"></i>
    </a>

    <a href="https://twitter.com/spencerldixon" target="_blank">
      <i class="fa-brands fa-x-twitter fa-xl"></i>
    </a>

    <a href="https://linkedin.com/in/spencerldixon" target="_blank">
      <i class="fa-brands fa-linkedin fa-xl"></i>
    </a>

    <a href="javascript:window.location.href='mailto:' + atob('c3BlbmNlcmxsb3lkZGl4b25AZ21haWwuY29t')">
      <i class="fa-solid fa-envelope fa-xl"></i>
    </a>

    <a href="http://localhost:4000/feed.xml">
      <i class="fa-solid fa-rss fa-xl"></i>
    </a>
  </div>
</div>




</div>

    </main>

    <!-- Highlight.js core -->
    <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.11.1/build/highlight.min.js"></script>
    <script>
    // Auto-detect & highlight all <pre><code class="language-..."> blocks
    document.addEventListener("DOMContentLoaded", (event) => {
      if (window.hljs) { hljs.highlightAll(); }
    });
    </script>
  </body>
</html>
